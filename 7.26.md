# 数据挖掘导论

结合昨天看的一部分，一起汇总。

## 5.6 组合方法（下）
* 提升方法
  * 为每个样本赋权值，如果它被误分类，提高它的权值，更容易被挑选到
  * 误差也是加权误差的形式
  * 如果错误率大于0.5，重新设定各权值为1/N
  * 倾向于被误分类的样本，有过拟合的潜在问题
* 随机森林
  + 从原始数据，创建随机变量，建立多决策树，再组合
  + 随机向量的生成方法：
    + 随机选择F个输入特征来进行分裂——Forest RI
    + 创建输入特征的线性组合（克服上面方法中，如果特征数目太小的问题）——Forest RC
    + 在决策树的每一个节点，从F个最佳划分中挑选一个（除非F够大，不然各个树会很相似）
+ 各种方法的比较，基本来讲，是装袋 < 提升 < RF

## 5.7 不平衡分类问题
+ 稀有类的问题，比如信用卡欺诈，比如癌症等，这些都是小概率事件，但我们就是要检测这些东西
+ 与PRML的一部分内容类似，见[这里](https://github.com/gylight/daily-report/blob/master/7.14.md)，那里是使用概率的角度来处理
+ 度量的方法，各自有偏向：
  + 精确度
  + 召回率
  + F-measure等等
+ 接受者操作特征曲线（ROC，receiver operating characteristic）
  + 一个好的分类模型应该尽可能靠近图的左上角
  + 一个随机的模型是对角线
  + 绘制的方法。选最小的为负类，选次小以下的为负类，逐步下去，得到一个曲线
  + 个人感觉，ROC是从这个模型的总体去衡量，而F-Measure等，只是考虑某个值
+ 代价敏感
  + 就是之前提到的矩阵，负类分为正类的代价应该更高（比如对于癌症来讲）
+ 基于抽样的方法
  + 不充分抽样，潜在有一些有效的样本没被抽样出来 -----> 聚焦的不充分抽样
  + 过分抽样，就是复制类别总数目小的样本，确保他们的决策边界不会被忽略，但是对噪声会有过拟合的问题
  + 上面两者的混合方法
  
