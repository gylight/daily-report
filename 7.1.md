# 数据挖掘导论 第三章 探索数据

+ 汇总统计
  + 频率
  + 众数。对连续数据无用，但可以更改分辨率（厘米改成分米等）、检测缺漏值等。
  + 百分位数
  + 位置度量：均值和中位数。均值对离群值很敏感，因此有截断均值。
  + 散布度量：极差和方差。
  + 协方差
+ 可视化
  + 茎叶图、直方图、盒状图等。
  + 事实表,感觉挺有用，只要离散化得好。

# 数据挖掘导论 第四章 分类

+ 划分方法
  + 选择1，熵，信息增益
  + 选择2，基尼不存度
  + 上两种的区别，在《集体智慧编程》上有说：熵和基尼不存度的主要区别在于，熵达到峰值的过程要相对慢一些。因此，熵对于混乱集合的“判罚”往往要更重一些。
  + 选择3，还可以用增益比率。《机器学习》上举的例子更合适：如果有一个属性是date，那么按照不同的date来进行分类，信息增益是最大的。但这样显然是有问题。
  + 连续属性的划分
  
+ 斜决策树，构造归纳

+ 过拟合
  + 噪声
  + 缺乏代表性样本
  + 多重比较过程。其实这个问题，是跟算法的机制有关？这里确定是否继续分裂节点，是判断信息增益与固定值MAX的大小（MAX不会随着子节点个数而变化）。而像《集体》书里，结束拆分过程是判断子节点熵之和与父节点熵的大小，就没有固定MAX的问题了？
  + 泛化误差估计
    + 再代入估计
    + 结合模型复杂度
      + 奥坎姆剃刀
      + 悲观误差估计
      + 最小描述长度原则
  
