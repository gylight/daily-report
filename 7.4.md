# 数据挖掘导论 第五章

## K-近邻
+ 消极学习方法 lazy
+ Rote分类器（全部匹配）
+ 多数表决
+ 加权
+ 《集体智慧》书里补充的知识点：
  + 为近邻分配权重的方法：
    + 反函数：1/dis,1/(dis+const)
    + 减法函数：常量值减去距离，会有项权重为0
    + 高斯函数：比减法函数，好处在于权重不会为0
  + 不同类型的变量：
    + 上面的权重是考虑dis，这里是考虑不同变量的重要性不同，区别对待
    + 归一化处理，同一值域
    + 用最优化算法确定缩放比例
    + 缩放的好处是，我们能很快发觉哪些变量是重要的，并且重要程度如何
## 贝叶斯分类器
+ 朴素贝叶斯
  + 假设各变量独立
  + 连续属性：
    + 离散化
    + 假设其服从某种概率分布
  + m估计
    + 避免概率会等于0的情况
  + 特点
    + 对孤立的噪声点健壮
    + 对无关属性健壮
    + 相关属性会降低性能
  + 贝叶斯误差率
